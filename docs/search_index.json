[
["nwinference.html", "5 Network inference: Running regressions with network data 5.1 Basic idea of Temporal Network Autocorrelation Model (TNAM) 5.2 TNAM-terms 5.3 Running TNAMs", " 5 Network inference: Running regressions with network data 5.1 Basic idea of Temporal Network Autocorrelation Model (TNAM) ## read data el &lt;- read.table(&#39;data_literatur_varia/Edgelist_highSchoolfriends.csv&#39;, sep = &quot;;&quot;, header = TRUE) dt &lt;- read.table(&#39;data_literatur_varia/Students_highSchoolAttributes.csv&#39;, sep = &quot;;&quot;, header = TRUE) ## create adjacency matrix for all sorts of friends (best friends, drinking buddies, school friends etc.) students &lt;- unique(c(el$studentID, el$friend.ID.code)) mat &lt;- matrix(0, nrow =length(students) , ncol = length(students)) colnames(mat) &lt;- as.character(students) rownames(mat) &lt;- as.character(students) mat[cbind(as.character(el$studentID), as.character(el$friend.ID.code))] &lt;- 1 ## create adjacency matrix for school friends matsf &lt;- matrix(0, nrow =length(students) , ncol = length(students)) colnames(matsf) &lt;- as.character(students) rownames(matsf) &lt;- as.character(students) matsf[cbind(as.character(el$studentID[el$school.friend == &#39;Yes&#39;]), as.character(el$friend.ID.code[el$school.friend == &#39;Yes&#39;]))] &lt;- 1 ## create adjacency matrix for going-out-friends (friends with whom you go out and have drinks with) matdf &lt;- matrix(0, nrow =length(students) , ncol = length(students)) colnames(matdf) &lt;- as.character(students) rownames(matdf) &lt;- as.character(students) matdf[cbind(as.character(el$studentID[el$go.out.friend == &#39;Yes&#39;]), as.character(el$friend.ID.code[el$go.out.friend == &#39;Yes&#39;]))] &lt;- 1 ## create attributes file that matches the adjacency matrix att &lt;- data.frame(&#39;studentID&#39; = rownames(mat)) ## add attributes # Grades in Math and French-Class att$grade.math.french &lt;- dt$marks.french.math.num[match(att$studentID, dt$studentID)] # Name of school class att$class &lt;- dt$class[match(att$studentID, dt$studentID)] # Gender att$gender &lt;- dt$gender[match(att$studentID, dt$studentID)] # Age att$age &lt;- dt$age[match(att$studentID, dt$studentID)] # Migration background att$migrationbg &lt;- dt$migration.bg[match(att$studentID, dt$studentID)] # Liking school att$liking.school &lt;- dt$likes.school.num[match(att$studentID, dt$studentID)] # Leisure time att$sport.hours &lt;- dt$sport.hours[match(att$studentID, dt$studentID)] att$tv.hours &lt;- dt$hr.spent.TV.num[match(att$studentID, dt$studentID)] att$friends.hours &lt;- dt$hr.spent.friends.num[match(att$studentID, dt$studentID)] att$reading.hours &lt;- dt$hr.spent.reading.num[match(att$studentID, dt$studentID)] # Values: Being successful &amp; Earning a lot att$agree.besuccessfull &lt;- dt$agree.be.successful.num[match(att$studentID, dt$studentID)] att$agree.earnalot &lt;- dt$aggree.earn.alot.num[match(att$studentID, dt$studentID)] # Values: Repecting elders &amp; Parental monitoring att$true.parentsinterested &lt;- dt$true.parents.interested.num[match(att$studentID, dt$studentID)] att$true.respectelderly &lt;- dt$agree.respect.elderly.num[match(att$studentID, dt$studentID)] 5.2 TNAM-terms To capture network dependencies in the data, several different tnam-terms can be used to calculate new variables that may affect the dependent variable (or more neutrally: is correlated with the dependent variable). Spatial Lags - where a standard variable is multiplied with an adjacency matrix to test whether network autocorrelation exists, meaning whether the behavior of my neighbors/friends affects my behavior (is correlated with my behavior - no matter which way the correlation points, i.e., whether I choose similar friends or whether my friends affect me or whether I influence my friends). Attribute similarity - using a spatial lag term, you compare the dependent variable of your friends to your own value in the dependent variable to see whether homophily (either influence or selection or both) is at work. Network effects - you can test the effect of network effects on the dependent variable, i.e., whether popularity affects a dependent variable or centrality scores correlate with the dependent variable. Find out more on tnam-terms by typing: ?&#39;tnam-terms&#39; 5.3 Running TNAMs 5.3.1 Purely exogenous factors - neglecting important network dependencies! fit1 &lt;- lm(grade.math.french ~ age + gender, data = att) summary(fit1) ## ## Call: ## lm(formula = grade.math.french ~ age + gender, data = att) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.5166 -0.5166 0.0142 0.6588 1.6588 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.64240 0.70978 7.949 2.83e-14 *** ## age -0.07229 0.04224 -1.712 0.0879 . ## gendermale 0.17541 0.10055 1.745 0.0820 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9051 on 338 degrees of freedom ## (27 observations deleted due to missingness) ## Multiple R-squared: 0.01636, Adjusted R-squared: 0.01054 ## F-statistic: 2.811 on 2 and 338 DF, p-value: 0.06158 Now these results are not reliable since we do not control for network dependencies among observations (=students). SE are overestimated, p-values are too low and estimates are also biased if we do not control for the fact that these observations potentially influence each other. 5.3.2 Checking for network autocorrelation Let’s add a netlag term for network dependency. This term measures whether your own performance (= measured by the grades achieved in the German class) correlates with the performance of your immediate friends. With the netlag()-function we can easily estimate the (average) performance of an ego’s friends. nldt &lt;- netlag(att$grade.math.french, mat) The netlag()-function creates a new data set with the following columns: 1. netlag.pathdist1 = performance of best friends 2. time = here a constant 3. node = nodeID 4. response = dependent variable = here performance We will adopt the first variable into our attributes data set and include it in the regression: att$grade.friends &lt;- netlag(att$grade.math.french, mat)[,1] fit2 &lt;- lm(grade.math.french ~ age + gender + grade.friends, data = att) summary(fit2) ## ## Call: ## lm(formula = grade.math.french ~ age + gender + grade.friends, ## data = att) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.5402 -0.4870 0.0133 0.6676 1.7154 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.573817 0.712216 7.826 6.57e-14 *** ## age -0.074396 0.042264 -1.760 0.0793 . ## gendermale 0.185680 0.100940 1.840 0.0667 . ## grade.friends 0.006659 0.005993 1.111 0.2673 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9048 on 337 degrees of freedom ## (27 observations deleted due to missingness) ## Multiple R-squared: 0.01995, Adjusted R-squared: 0.01122 ## F-statistic: 2.287 on 3 and 337 DF, p-value: 0.07852 The normal netlag()-function uses no normalization and simply adds all the values of the friends together. I prefer to use an average effect, where the performance is averaged over the number of friends I have. att$avg.grade.ofriends &lt;- netlag(att$grade.math.french, mat, normalization = &#39;row&#39;)[,1] att$avg.grade.ifriends &lt;- netlag(att$grade.math.french, mat, normalization = &#39;column&#39;)[,1] fit3 &lt;- lm(grade.math.french ~ age + gender + avg.grade.ofriends, data = att) summary(fit3) ## ## Call: ## lm(formula = grade.math.french ~ age + gender + avg.grade.ofriends, ## data = att) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.54831 -0.50981 -0.00981 0.71351 1.70279 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.30974 0.72837 7.290 2.23e-12 *** ## age -0.07413 0.04208 -1.761 0.0791 . ## gendermale 0.18675 0.10034 1.861 0.0636 . ## avg.grade.ofriends 0.08580 0.04512 1.902 0.0581 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9016 on 337 degrees of freedom ## (27 observations deleted due to missingness) ## Multiple R-squared: 0.0268, Adjusted R-squared: 0.01814 ## F-statistic: 3.094 on 3 and 337 DF, p-value: 0.02713 The netlag()-term allows for more distand network effects: att$avg.grades.ofriendoffriends &lt;- netlag(att$grade.math.french, mat, normalization = &#39;row&#39;, pathdist = 2)[,1] fit4 &lt;- lm(grade.math.french ~ age + gender + avg.grade.ofriends + avg.grades.ofriendoffriends, data = att) summary(fit4) ## ## Call: ## lm(formula = grade.math.french ~ age + gender + avg.grade.ofriends + ## avg.grades.ofriendoffriends, data = att) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.53735 -0.51553 -0.00669 0.69880 1.76122 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.31759 0.72893 7.295 2.16e-12 *** ## age -0.07093 0.04233 -1.676 0.0948 . ## gendermale 0.17945 0.10089 1.779 0.0762 . ## avg.grade.ofriends 0.10551 0.05238 2.014 0.0448 * ## avg.grades.ofriendoffriends -0.06924 0.09330 -0.742 0.4585 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9022 on 336 degrees of freedom ## (27 observations deleted due to missingness) ## Multiple R-squared: 0.02839, Adjusted R-squared: 0.01683 ## F-statistic: 2.455 on 4 and 336 DF, p-value: 0.04565 5.3.3 Checking for Clique effects Instead of checking for correlations between ego’s behavior and the average behavior of ego’s friends you can also check for clique effects: here, the average performance is calculated not only for direct friends but also for indirect friends that are part of ego’s clique. att$clique.grades &lt;- cliquelag(att$grade.math.french, mat)[,1] fit4 &lt;- lm(grade.math.french ~ age + gender + clique.grades, data = att) summary(fit4) ## ## Call: ## lm(formula = grade.math.french ~ age + gender + clique.grades, ## data = att) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.56359 -0.50301 0.01606 0.66415 1.68883 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.587911 0.715100 7.814 7.12e-14 *** ## age -0.071803 0.042277 -1.698 0.0904 . ## gendermale 0.187352 0.102230 1.833 0.0677 . ## clique.grades 0.004487 0.006761 0.664 0.5074 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9059 on 337 degrees of freedom ## (27 observations deleted due to missingness) ## Multiple R-squared: 0.01764, Adjusted R-squared: 0.008897 ## F-statistic: 2.017 on 3 and 337 DF, p-value: 0.1113 5.3.4 Checking for centrality effects att$indegree &lt;- degree(mat, cmode = &#39;indegree&#39;) fit5a &lt;- lm(grade.math.french ~ age + gender + avg.grade.ofriends + indegree, data = att) summary(fit5a) ## ## Call: ## lm(formula = grade.math.french ~ age + gender + avg.grade.ofriends + ## indegree, data = att) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.48733 -0.52220 -0.00039 0.69348 1.68315 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.30653 0.72887 7.280 2.38e-12 *** ## age -0.07130 0.04229 -1.686 0.0927 . ## gendermale 0.18111 0.10070 1.799 0.0730 . ## avg.grade.ofriends 0.08938 0.04540 1.969 0.0498 * ## indegree -0.01702 0.02298 -0.741 0.4595 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9022 on 336 degrees of freedom ## (27 observations deleted due to missingness) ## Multiple R-squared: 0.02839, Adjusted R-squared: 0.01682 ## F-statistic: 2.454 on 4 and 336 DF, p-value: 0.0457 att$outdegree &lt;- degree(mat, cmode = &#39;outdegree&#39;) fit5b &lt;- lm(grade.math.french ~ age + gender + avg.grade.ofriends + outdegree, data = att) summary(fit5b) ## ## Call: ## lm(formula = grade.math.french ~ age + gender + avg.grade.ofriends + ## outdegree, data = att) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.53743 -0.52950 -0.00305 0.69813 1.71214 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.32109 0.72908 7.298 2.12e-12 *** ## age -0.07280 0.04216 -1.727 0.0851 . ## gendermale 0.17998 0.10086 1.784 0.0753 . ## avg.grade.ofriends 0.09566 0.04722 2.026 0.0436 * ## outdegree -0.02092 0.02937 -0.712 0.4768 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9023 on 336 degrees of freedom ## (27 observations deleted due to missingness) ## Multiple R-squared: 0.02827, Adjusted R-squared: 0.0167 ## F-statistic: 2.444 on 4 and 336 DF, p-value: 0.04649 att$betweenness &lt;- betweenness(mat) fit5c &lt;- lm(grade.math.french ~ age + gender + avg.grade.ofriends + betweenness, data = att) summary(fit5c) ## ## Call: ## lm(formula = grade.math.french ~ age + gender + avg.grade.ofriends + ## betweenness, data = att) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.5533 -0.5063 -0.0064 0.7179 1.7079 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.300e+00 7.303e-01 7.257 2.76e-12 *** ## age -7.367e-02 4.217e-02 -1.747 0.0816 . ## gendermale 1.871e-01 1.005e-01 1.862 0.0635 . ## avg.grade.ofriends 8.401e-02 4.565e-02 1.840 0.0666 . ## betweenness 5.164e-06 1.884e-05 0.274 0.7842 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9029 on 336 degrees of freedom ## (27 observations deleted due to missingness) ## Multiple R-squared: 0.02702, Adjusted R-squared: 0.01544 ## F-statistic: 2.333 on 4 and 336 DF, p-value: 0.05558 5.3.5 Attribute similarity You can also check whether students who share some attribute also share performance scores. We could test this using the ‘sport.hours’ variable that measures the hours a student spends doing sports/exercises. att$attrsim.sporthr &lt;- attribsim(att$grade.math.french, att$sport.hours, match = FALSE)[,1] fit6 &lt;- lm(grade.math.french ~ age + gender + avg.grade.ofriends + attrsim.sporthr, data = att) summary(fit6) 5.3.6 A fuller model Controlling for gender and age is probably an underspecification, which leads to biased estimates (i.e., coefficients and standard errors). For sake of teaching a sparse model was chosen, but: always make sure you include all (potential) control variables! Do this by: - comparing BIC scores between models (lower BIC = better model) - comparing R^2 between models - checking prediction performance of your model (advanced topic) If you neglect … HIER WEITER "]
]
